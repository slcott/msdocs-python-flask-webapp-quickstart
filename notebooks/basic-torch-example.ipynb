{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6401b57b-0cc0-44ac-b58e-92bb59513c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87612ff6-e000-41f4-ad49-7fdcd80c472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8d2a3bb-532e-4ab8-b3b8-a01dcfa70839",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GPT4Tokenizer' from 'transformers' (C:\\Users\\RiccardelliScott\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT4Tokenizer\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GPT4Tokenizer' from 'transformers' (C:\\Users\\RiccardelliScott\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import GPT4Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d400efef-8cc0-457c-97a1-cae1a9f4157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.0136, -0.0204,  0.0139,  ...,  0.0396, -0.0144, -0.0282],\n",
      "        [-0.0172, -0.0105, -0.0037,  ..., -0.0055,  0.0184, -0.0445],\n",
      "        [ 0.0071,  0.0127, -0.0220,  ...,  0.0230, -0.0150,  0.0017],\n",
      "        ...,\n",
      "        [ 0.0074,  0.0544, -0.0129,  ...,  0.0328, -0.0091, -0.0135],\n",
      "        [-0.0039,  0.0338,  0.0003,  ...,  0.0374, -0.0225,  0.0062],\n",
      "        [ 0.0340,  0.0738, -0.0202,  ...,  0.0273,  0.0099, -0.0370]])\n",
      "torch.Size([10, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "# sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "sentences = [\n",
    "  \"Beyond Mars (1 hr 15 min): Join space enthusiasts as they speculate about extraterrestrial life and the mysteries of distant planets.\",\n",
    "  \"Jazz under stars (55 min): Experience a captivating night in New Orleans, where jazz melodies echo under the moonlit sky.\",\n",
    "  \"Mysteries of the deep (1 hr 30 min): Dive with marine explorers into the uncharted caves of our oceans and uncover their hidden wonders.\",\n",
    "  \"Rediscovering lost melodies (48 min): Journey through time to explore the resurgence of vinyl culture and its timeless appeal.\",\n",
    "  \"Tales from the tech frontier (1 hr 5 min): Navigate the complex terrain of AI ethics, understanding its implications and challenges.\",\n",
    "  \"The soundscape of silence (30 min): Traverse the globe with sonic explorers to find the world's most serene and silent spots.\",\n",
    "  \"Decoding dreams (1 hr 22 min): Step into the realm of the subconscious, deciphering the intricate narratives woven by our dreams.\",\n",
    "  \"Time capsules (50 min): Revel in the bizarre, endearing, and profound discoveries that unveil the quirks of a century past.\",\n",
    "  \"Frozen in time (1 hr 40 min): Embark on an icy expedition, unearthing secrets hidden within the majestic ancient glaciers.\",\n",
    "  \"Songs of the Sea (1 hr): Dive deep with marine biologists to understand the intricate whale songs echoing in our vast oceans.\"\n",
    "]\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n",
    "print(sentence_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa2e9947-93cf-4937-834b-442754d381a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT4Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m sentence_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaxophone nightclub\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m GPT4Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXenova/text-embedding-ada-002\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXenova/text-embedding-ada-002\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Tokenize sentences\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GPT4Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "sentence_test = [\"saxophone nightclub\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "# tokenizer = GPT4Tokenizer.from_pretrained('Xenova/text-embedding-ada-002')\n",
    "# model = AutoModel.from_pretrained('Xenova/text-embedding-ada-002')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentence_test, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "query_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "query_embeddings = F.normalize(query_embeddings, p=1, dim=1)\n",
    "\n",
    "print(\"query embeddings:\")\n",
    "# print(sentence_test_embeddings)\n",
    "print(query_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31fc6aae-209d-4208-ad07-9949aabb9519",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 128])\n",
      "tensor([-0.0453,  0.1228,  0.0009,  0.0729, -0.0021, -0.0017, -0.1844, -0.1232,\n",
      "        -0.0430,  0.0496, -0.1468, -0.1631, -0.1360, -0.0114,  0.0740,  0.1488,\n",
      "         0.1291, -0.0026, -0.0227, -0.0555,  0.1586,  0.1117, -0.0732, -0.0257,\n",
      "        -0.0055,  0.0949, -0.1227,  0.0037,  0.0337, -0.0376,  0.0134, -0.0530,\n",
      "        -0.0272, -0.0910, -0.1145,  0.0276, -0.0508,  0.0386,  0.0323, -0.1203,\n",
      "         0.0397,  0.0400,  0.0333,  0.0293,  0.0678,  0.1561, -0.0478,  0.0617,\n",
      "         0.0923,  0.2419, -0.0097,  0.1034,  0.1016,  0.0121, -0.0575, -0.0545,\n",
      "         0.0419,  0.0501,  0.0737, -0.1744,  0.1137, -0.0907,  0.0493, -0.1207,\n",
      "         0.0783,  0.0104,  0.0577, -0.0845, -0.1083, -0.0455, -0.0288, -0.0405,\n",
      "         0.1506, -0.0573,  0.0980,  0.1049, -0.1113, -0.0095,  0.0667,  0.0445,\n",
      "         0.0080,  0.1370, -0.0025, -0.0019,  0.0292, -0.0431,  0.0181,  0.0515,\n",
      "        -0.0459, -0.1767,  0.0152, -0.0077,  0.1535,  0.0208,  0.1274, -0.0894,\n",
      "        -0.0616,  0.1334,  0.0466, -0.0024])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "print(input1.shape)\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(input1, input2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b99a4cfa-f31c-4745-ae0a-463f46a9e61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1847)\n",
      "tensor(0.4688)\n",
      "tensor(0.1160)\n",
      "tensor(0.3309)\n",
      "tensor(0.0200)\n",
      "tensor(0.2734)\n",
      "tensor(0.0690)\n",
      "tensor(0.1463)\n",
      "tensor(0.0623)\n",
      "tensor(0.2213)\n",
      "1 tensor(0.4688)\n",
      "Jazz under stars (55 min): Experience a captivating night in New Orleans, where jazz melodies echo under the moonlit sky.\n"
     ]
    }
   ],
   "source": [
    "best_i, best_score = 0, 0\n",
    "for i, sentence_embedding in enumerate(sentence_embeddings):\n",
    "    # print(sentence_embedding.shape)\n",
    "    # print(sentence_test_embeddings[0].shape)\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "    score = cos(sentence_embedding, query_embeddings[0])\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_i = i\n",
    "    print(score)\n",
    "print(best_i, best_score)\n",
    "print(sentences[best_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a657d5d3-89dd-4549-9360-46a76ca78162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1847, 0.4688, 0.1160, 0.3309, 0.0200, 0.2734, 0.0690, 0.1463, 0.0623,\n",
      "        0.2213])\n",
      "tensor(1)\n",
      "Jazz under stars (55 min): Experience a captivating night in New Orleans, where jazz melodies echo under the moonlit sky.\n"
     ]
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "scores = cos(sentence_embeddings, query_embeddings[0])\n",
    "print(scores)\n",
    "best_i = torch.argmax(scores)\n",
    "print(best_i)\n",
    "print(sentences[best_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd01a01-ad12-4fe7-843c-dbe76b10d104",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Use a vector database\n",
    "\n",
    "or use a nearest neighbors algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3b77c-16d4-4b5a-a445-c22f57b9a739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
